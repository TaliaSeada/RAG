From Basics to Advanced: Exploring LangGraph · Published in Towards Data Science 21 min read · Aug 15, 2024 Listen Share Image by DALL-E 3 LangGraph basics Single-agent workflow Building agent from scratch CH_HOST = ' # default address import requests def get_clickhouse_data(query, host = CH_HOST, connection_timeout = 1500): r = requests.post(host, params = {'query': query}, timeout = connection_timeout) if r.status_code == 200: return r.text else: return 'Database returned the following erro + r.text execute_sql pydantic from langchain_core.tools import tool from pydantic.v1 import BaseModel, Field from typing import Optional class SQLQuery(BaseModel): query: str = Field(description="SQL query to execute") @tool(args_schema = SQLQuery) def execute_sql(query: str) -> str: """Returns the result of SQL query execution""" return get_clickhouse_data(query) print(f''' name: {execute_sql.name} description: {execute_sql.description} arguments: {execute_sql.args} ''') # name: execute_sql # description: Returns the result of SQL query execution # arguments: {'query': {'title': 'Query', 'description': # 'SQL query to execute', 'type': 'string'}} # useful imports from langgraph.graph import StateGraph, END from typing import TypedDict, Annotated import operator from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage # defining agent state class AgentState(TypedDict): messages: Annotated[list[AnyMessage], operator.add] AgentState messages AnyMessage operator.add __init__ class SQLAgent: # initialising the object def __init__(self, model, tools, system_prompt = ""): self.system_prompt = system_prompt # initialising graph with a state graph = StateGraph(AgentState) # adding nodes graph.add_node("llm", self.call_llm) graph.add_node("function", self.execute_function) graph.add_conditional_edges( "llm", self.exists_function_calling, {True: "function", False: END} ) graph.add_edge("function", "llm") # setting starting point graph.set_entry_point("llm") self.graph = graph.compile() self.tools = {t.name: t for t in tools} self.model = model.bind_tools(tools) llm action llm exists_function_calling END function llm call_llm class SQLAgent: <...> def call_llm(self, state: AgentState): messages = state['messages'] # adding system prompt if it's defined if self.system_prompt: messages = [SystemMessage(content=self.system_prompt)] + messages # calling LLM message = self.model.invoke(messages) return {'messages': [message]} operator.add execute_function message.tool_calls class SQLAgent: <...> def execute_function(self, state: AgentState): tool_calls = state['messages'][-1].tool_calls results = [] for tool in tool_calls: # checking whether tool name is correct if not t['name'] in self.tools: # returning error to the agent result = "Error: There's no such tool, please, try again" else: # getting result from the tool result = self.tools[t['name']].invoke(t['args']) results.append( ToolMessage( tool_call_id=t['id'], name=t['name'], content=str(result) ) ) return {'messages': results} messages class SQLAgent: <...> def exists_function_calling(self, state: AgentState): result = state['messages'][-1] return len(result.tool_calls) > 0 import os # setting up credentioals os.environ["OPENAI_MODEL_NAME"]='gpt-4o-mini' os.environ["OPENAI_API_KEY"] = '<your_api_key>' # system prompt prompt = '''You are a senior expert in SQL and data analysis. So, you can help the team to gather needed data to power their decisions. You are very accurate and take into account all the nuances in data. Your goal is to provide the detailed documentation for the table in database that will help users.''' model = ChatOpenAI(model="gpt-4o-mini") doc_agent = SQLAgent(model, [execute_sql], system=prompt) pygraphviz ! brew install graphviz ! python3 -m pip install -U --no-cache-dir \ --config-settings="--global-option=build_ext" \ --config-settings="--global-option=-I$(brew --prefix graphviz)/include/" \ --config-settings="--global-option=-L$(brew --prefix graphviz)/lib/" \ pygraphviz from IPython.display import Image Image(doc_agent.graph.get_graph().draw_png()) HumanMessage messages = [HumanMessage(content="What info do we have in ecommerce_db.users table?")] result = doc_agent.graph.invoke({"messages": messages}) result describe ecommerce.db_users result['messages'] # [ # HumanMessage(content='What info do we have in ecommerce_db.users table?'), # AIMessage(content='', tool_calls=[{'name': 'execute_sql', 'args': {'query': 'DESCRIBE ecommerce_db.users;'}, 'id': 'call_qZbDU9Coa2tMjU ARcX36h0ax', 'type': 'tool_call'}]), # ToolMessage(content='user_id\tUInt64\t\t\t\t\t\ncountry\tString\t\t\t\t\t\nis_active\tUInt8\t\t\t\t\t\nage\tUInt64\t\t\t\t\t\n', name='execute_sql', t ool_call_id='call_qZbDU9Coa2tMjUARcX36h0ax'), # AIMessage(content='The `ecommerce_db.users` table contains the following columns: <...>') # ] print(result['messages'][-1].content) # The `ecommerce_db.users` table contains the following columns: # 1. **user_id**: `UInt64` - A unique identifier for each user. # 2. **country**: `String` - The country where the user is located. # 3. **is_active**: `UInt8` - Indicates whether the user is active (1) or inactive (0). # 4. **age**: `UInt64` - The age of the user. Using prebuilt agents from langgraph.prebuilt import create_react_agent prebuilt_doc_agent = create_react_agent(model, [execute_sql], state_modifier = system_prompt) Persistence and streaming from langgraph.checkpoint.sqlite import SqliteSaver memory = SqliteSaver.from_conn_string(":memory:") prebuilt_doc_agent = create_react_agent(model, [execute_sql], checkpointer=memory) class SQLAgent: def __init__(self, model, tools, system_prompt = ""): <...> self.graph = graph.compile(checkpointer=memory) <...> pretty_print # defining thread thread = {"configurable": {"thread_id": "1"}} messages = [HumanMessage(content="What info do we have in ecommerce_db.users table?")] for event in prebuilt_doc_agent.stream({"messages": messages}, thread): for v in event.values(): v['messages'][-1].pretty_print() # ================================== Ai Message ================================== # Tool Calls: # execute_sql (call_YieWiChbFuOlxBg8G1jDJitR) # Call ID: call_YieWiChbFuOlxBg8G1jDJitR # Args: # query: SELECT * FROM ecommerce_db.users LIMIT 1; # ================================= Tool Message ================================= # Name: execute_sql # 1000001 United Kingdom 0 70 # # ================================== Ai Message ================================== # # The `ecommerce_db.users` table contains at least the following information for users: # # - **User ID** (e.g., `1000001`) # - **Country** (e.g., `United Kingdom`) # - **Some numerical value** (e.g., `0`) # - **Another numerical value** (e.g., `70`) # # The specific meaning of the numerical values and additional columns # is not clear from the single row retrieved. Would you like more details # or a broader query? followup_messages = [HumanMessage(content="I would like to know the column names and types. Maybe you could look it up in database using describe.")] for event in prebuilt_doc_agent.stream({"messages": followup_messages}, thread): for v in event.values(): v['messages'][-1].pretty_print() # ================================== Ai Message ================================== # Tool Calls: # execute_sql (call_sQKRWtG6aEB38rtOpZszxTVs) # Call ID: call_sQKRWtG6aEB38rtOpZszxTVs # Args: # query: DESCRIBE ecommerce_db.users; # ================================= Tool Message ================================= # Name: execute_sql # # user_id UInt64 # country String # is_active UInt8 # age UInt64 # # ================================== Ai Message ================================== # # The `ecommerce_db.users` table has the following columns along with their data types: # # | Column Name | Data Type | # |-------------|-----------| # | user_id | UInt64 | # | country | String | # | is_active | UInt8 | # | age | UInt64 | # # If you need further information or assistance, feel free to ask! new_thread = {"configurable": {"thread_id": "42"}} followup_messages = [HumanMessage(content="I would like to know the column names and types. Maybe you could look it up in database using describe.")] for event in prebuilt_doc_agent.stream({"messages": followup_messages}, new_thread): for v in event.values(): v['messages'][-1].pretty_print() # ================================== Ai Message ================================== # Tool Calls: # execute_sql (call_LrmsOGzzusaLEZLP9hGTBGgo) # Call ID: call_LrmsOGzzusaLEZLP9hGTBGgo # Args: # query: DESCRIBE your_table_name; # ================================= Tool Message ================================= # Name: execute_sql # # Database returned the following error: # : 60. DB::Exception: Table default.your_table_name does not exist. (UNKNOWN_TABLE) (version 23.12.1.414 (official build)) # # ================================== Ai Message ================================== # # It seems that the table `your_table_name` does not exist in the database. # Could you please provide the actual name of the table you want to describe? Multi-Agent Systems question question_type answer feedback class MultiAgentState(TypedDict): question: str question_type: str answer: str feedback: str question_category_prompt = '''You are a senior specialist of analytical support. Your task is to classify the incoming questions. Depending on your answer, question will be routed to the right team, so your task is crucial for our team. There are 3 possible question types: - DATABASE - questions related to our database (tables or fields) - LANGCHAIN- questions related to LangGraph or LangChain libraries - GENERAL - general questions Return in the output only one word (DATABASE, LANGCHAIN or GENERAL). ''' def router_node(state: MultiAgentState): messages = [ SystemMessage(content=question_category_prompt), HumanMessage(content=state['question']) ] model = ChatOpenAI(model="gpt-4o-mini") response = model.invoke(messages) return {"question_type": response.content} memory = SqliteSaver.from_conn_string(":memory:") builder = StateGraph(MultiAgentState) builder.add_node("router", router_node) builder.set_entry_point("router") builder.add_edge('router', END) graph = builder.compile(checkpointer=memory) thread = {"configurable": {"thread_id": "1"}} for s in graph.stream({ 'question': "Does LangChain support Ollama?", }, thread): print(s) # {'router': {'question_type': 'LANGCHAIN'}} thread = {"configurable": {"thread_id": "2"}} for s in graph.stream({ 'question': "What info do we have in ecommerce_db.users table?", }, thread): print(s) # {'router': {'question_type': 'DATABASE'}} thread = {"configurable": {"thread_id": "3"}} for s in graph.stream({ 'question': "How are you?", }, thread): print(s) # {'router': {'question_type': 'GENERAL'}} # database expert sql_expert_system_prompt = ''' You are an expert in SQL, so you can help the team to gather needed data to power their decisions. You are very accurate and take into account all the nuances in data. You use SQL to get the data before answering the question. ''' def sql_expert_node(state: MultiAgentState): model = ChatOpenAI(model="gpt-4o-mini") sql_agent = create_react_agent(model, [execute_sql], state_modifier = sql_expert_system_prompt) messages = [HumanMessage(content=state['question'])] result = sql_agent.invoke({"messages": messages}) return {'answer': result['messages'][-1].content} # search expert from langchain_community.tools.tavily_search import TavilySearchResults os.environ["TAVILY_API_KEY"] = 'tvly-...' tavily_tool = TavilySearchResults(max_results=5) search_expert_system_prompt = ''' You are an expert in LangChain and other technologies. Your goal is to answer questions based on results provided by search. You don't add anything yourself and provide only information baked by other sources. ''' def search_expert_node(state: MultiAgentState): model = ChatOpenAI(model="gpt-4o-mini") sql_agent = create_react_agent(model, [tavily_tool], state_modifier = search_expert_system_prompt) messages = [HumanMessage(content=state['question'])] result = sql_agent.invoke({"messages": messages}) return {'answer': result['messages'][-1].content} # general model general_prompt = '''You're a friendly assistant and your goal is to answer general questions. Please, don't provide any unchecked information and just tell that you don't know if you don't have enough info. ''' def general_assistant_node(state: MultiAgentState): messages = [ SystemMessage(content=general_prompt), HumanMessage(content=state['question']) ] model = ChatOpenAI(model="gpt-4o-mini") response = model.invoke(messages) return {"answer": response.content} def route_question(state: MultiAgentState): return state['question_type'] builder = StateGraph(MultiAgentState) builder.add_node("router", router_node) builder.add_node('database_expert', sql_expert_node) builder.add_node('langchain_expert', search_expert_node) builder.add_node('general_assistant', general_assistant_node) builder.add_conditional_edges( "router", route_question, {'DATABASE': 'database_expert', 'LANGCHAIN': 'langchain_expert', 'GENERAL': 'general_assistant'} ) builder.set_entry_point("router") builder.add_edge('database_expert', END) builder.add_edge('langchain_expert', END) builder.add_edge('general_assistant', END) graph = builder.compile(checkpointer=memory) thread = {"configurable": {"thread_id": "2"}} results = [] for s in graph.stream({ 'question': "What info do we have in ecommerce_db.users table?", }, thread): print(s) results.append(s) print(results[-1]['database_expert']['answer']) # The `ecommerce_db.users` table contains the following columns: # 1. **User ID**: A unique identifier for each user. # 2. **Country**: The country where the user is located. # 3. **Is Active**: A flag indicating whether the user is active (1 for active, 0 for inactive). # 4. **Age**: The age of the user. # Here are some sample entries from the table: # # | User ID | Country | Is Active | Age | # |---------|----------------|-----------|-----| # | 1000001 | United Kingdom | 0 | 70 | # | 1000002 | France | 1 | 87 | # | 1000003 | France | 1 | 88 | # | 1000004 | Germany | 1 | 25 | # | 1000005 | Germany | 1 | 48 | # # This gives an overview of the user data available in the table. thread = {"configurable": {"thread_id": "42"}} results = [] for s in graph.stream({ 'question': "Does LangChain support Ollama?", }, thread): print(s) results.append(s) print(results[-1]['langchain_expert']['answer']) # Yes, LangChain supports Ollama. Ollama allows you to run open-source # large language models, such as Llama 2, locally, and LangChain provides # a flexible framework for integrating these models into applications. # You can interact with models run by Ollama using LangChain, and there are # specific wrappers and tools available for this integration. # # For more detailed information, you can visit the following resources: # - [LangChain and Ollama Integration]( # - [ChatOllama Documentation]( # - [Medium Article on Ollama and LangChain]( Adding human-in-the-loop interactions human editor Human node: Editor node: def human_feedback_node(state: MultiAgentState): pass editor_prompt = '''You're an editor and your goal is to provide the final answer to the customer, taking into account the feedback. You don't add any information on your own. You use friendly and professional tone. In the output please provide the final answer to the customer without additional comments. Here's all the information you need. Question from customer: ---- {question} ---- Draft answer: ---- {answer} ---- Feedback: ---- {feedback} ---- ''' def editor_node(state: MultiAgentState): messages = [ SystemMessage(content=editor_prompt.format(question = state['question'], answer = state['answer'], feedback = state['feedback'])) ] model = ChatOpenAI(model="gpt-4o-mini") response = model.invoke(messages) return {"answer": response.content} builder = StateGraph(MultiAgentState) builder.add_node("router", router_node) builder.add_node('database_expert', sql_expert_node) builder.add_node('langchain_expert', search_expert_node) builder.add_node('general_assistant', general_assistant_node) builder.add_node('human', human_feedback_node) builder.add_node('editor', editor_node) builder.add_conditional_edges( "router", route_question, {'DATABASE': 'database_expert', 'LANGCHAIN': 'langchain_expert', 'GENERAL': 'general_assistant'} ) builder.set_entry_point("router") builder.add_edge('database_expert', 'human') builder.add_edge('langchain_expert', 'human') builder.add_edge('general_assistant', 'human') builder.add_edge('human', 'editor') builder.add_edge('editor', END) graph = builder.compile(checkpointer=memory, interrupt_before = ['human']) thread = {"configurable": {"thread_id": "2"}} for event in graph.stream({ 'question': "What are the types of fields in ecommerce_db.users table?", }, thread): print(event) # {'question_type': 'DATABASE', 'question': 'What are the types of fields in ecommerce_db.users table?'} # {'router': {'question_type': 'DATABASE'}} # {'database_expert': {'answer': 'The `ecommerce_db.users` table has the following field **user_id**: UInt64\n2. **country**: String\n 3. **is_active**: UInt8\n4. **age**: UInt64'}} user_input = input("Do I need to change anything in the answer?") # Do I need to change anything in the answer? # It looks wonderful. Could you only make it a bit friendlier please? graph.update_state(thread, {"feedback": user_input}, as_node="human") editor print(graph.get_state(thread).values['feedback']) # It looks wonderful. Could you only make it a bit friendlier please? print(graph.get_state(thread).next) # ('editor',) None for event in graph.stream(None, thread, stream_mode="values"): print(event) print(event['answer']) # Hello! The `ecommerce_db.users` table has the following fields: # 1. **user_id**: UInt64 # 2. **country**: String # 3. **is_active**: UInt8 # 4. **age**: UInt64 # Have a nice day! from langchain_community.tools import HumanInputRun human_tool = HumanInputRun() editor_agent_prompt = '''You're an editor and your goal is to provide the final answer to the customer, taking into the initial question. If you need any clarifications or need feedback, please, use human. Always reach out to human to get the feedback before final answer. You don't add any information on your own. You use friendly and professional tone. In the output please provide the final answer to the customer without additional comments. Here's all the information you need. Question from customer: ---- {question} ---- Draft answer: ---- {answer} ---- ''' model = ChatOpenAI(model="gpt-4o-mini") editor_agent = create_react_agent(model, [human_tool]) messages = [SystemMessage(content=editor_agent_prompt.format(question = state['question'], answer = state['answer']))] editor_result = editor_agent.invoke({"messages": messages}) # Is the draft answer complete and accurate for the customer's question about the types of fields in the ecommerce_db.users table? # Yes, but could you please make it friendlier. print(editor_result['messages'][-1].content) # The `ecommerce_db.users` table has the following fields: # 1. **user_id**: UInt64 # 2. **country**: String # 3. **is_active**: UInt8 # 4. **age**: UInt64 # # If you have any more questions, feel free to ask! def editor_agent_node(state: MultiAgentState): model = ChatOpenAI(model="gpt-4o-mini") editor_agent = create_react_agent(model, [human_tool]) messages = [SystemMessage(content=editor_agent_prompt.format(question = state['question'], answer = state['answer']))] result = editor_agent.invoke({"messages": messages}) return {'answer': result['messages'][-1].content} builder = StateGraph(MultiAgentState) builder.add_node("router", router_node) builder.add_node('database_expert', sql_expert_node) builder.add_node('langchain_expert', search_expert_node) builder.add_node('general_assistant', general_assistant_node) builder.add_node('editor', editor_agent_node) builder.add_conditional_edges( "router", route_question, {'DATABASE': 'database_expert', 'LANGCHAIN': 'langchain_expert', 'GENERAL': 'general_assistant'} ) builder.set_entry_point("router") builder.add_edge('database_expert', 'editor') builder.add_edge('langchain_expert', 'editor') builder.add_edge('general_assistant', 'editor') builder.add_edge('editor', END) graph = builder.compile(checkpointer=memory) thread = {"configurable": {"thread_id": "42"}} results = [] for event in graph.stream({ 'question': "What are the types of fields in ecommerce_db.users table?", }, thread): print(event) results.append(event) Summary Reference Llm Data Science Artificial Intelligence Editors Pick Deep Dives 1 Follow 12.3K Followers · Writer for TDoawtaa r&d sP rDoadtuac St Acineanlcyetics Lead at Wise | ClickHouse Evangelist